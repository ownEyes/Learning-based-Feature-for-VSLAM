{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs_and_unique_paths_from_hdf5(hdf5_file_path: str, hdf5_folder: str):\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "        loaded_pairs = []\n",
    "        unique_paths = set()\n",
    "\n",
    "        # Function to convert a single relative path back to an absolute path\n",
    "        def make_absolute(rel_path):\n",
    "            # Decode if the path is a byte string\n",
    "            if isinstance(rel_path, bytes):\n",
    "                rel_path = rel_path.decode('utf-8')\n",
    "            parts = rel_path.split('/')\n",
    "            new_parts = []\n",
    "            for part in parts:\n",
    "                if part == 'sun3d_extracted' or part == '..':\n",
    "                    continue\n",
    "                new_parts.append(part)\n",
    "            corrected_path = '/'.join(new_parts)\n",
    "            absolute_path = os.path.join(hdf5_folder, corrected_path)\n",
    "            return absolute_path\n",
    "\n",
    "        def process_paths(img_paths_array) -> tuple:\n",
    "            paths = tuple(make_absolute(path) for path in img_paths_array)\n",
    "            unique_paths.update(paths)\n",
    "            return paths\n",
    "\n",
    "        pairs_group = hdf['pairs']\n",
    "        for pair_name in pairs_group:\n",
    "            pair_group = pairs_group[pair_name]\n",
    "            img_paths_array = pair_group['img_paths'][()]\n",
    "            img_paths = process_paths(img_paths_array)\n",
    "            points1 = torch.tensor(pair_group['points1'][()])\n",
    "            pos_points2 = torch.tensor(pair_group['pos_points2'][()])\n",
    "            neg_points2 = torch.tensor(pair_group['neg_points2'][()])\n",
    "            loaded_pairs.append({\n",
    "                'img_paths': img_paths,\n",
    "                'points1': points1,\n",
    "                'pos_points2': pos_points2,\n",
    "                'neg_points2': neg_points2\n",
    "            })\n",
    "\n",
    "    return loaded_pairs, unique_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "output_path = os.path.join(\n",
    "    current_directory, os.pardir, os.pardir, 'datasets', 'sun3d_training')\n",
    "hdf5_file_path = os.path.join(output_path, 'pairs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pairs, unique_paths = load_pairs_and_unique_paths_from_hdf5(\n",
    "    hdf5_file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_unique_paths_to_file(unique_paths: set, file_path: str):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for path in sorted(unique_paths):\n",
    "            file.write(path + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_path = os.path.join(output_path, 'unique_image_paths.txt')\n",
    "write_unique_paths_to_file(unique_paths, txt_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros2_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
